{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EENlZvOtPDZ6"
      },
      "source": [
        "# Quantization tutorial\n",
        "\n",
        "This tutorial shows how to do post-training static quantization, as well as illustrating two more advanced techniques - per-channel quantization and quantization-aware training - to further improve the model’s accuracy. The task is to classify MNIST digits with a simple LeNet architecture.\n",
        "\n",
        "\n",
        "Thsi is a mimialistic tutorial to show you a starting point for quantisation in PyTorch. For theory and more in-depth explanations, Please check out: [Quantizing deep convolutional networks for efficient inference: A whitepaper\n",
        "](https://arxiv.org/abs/1806.08342).\n",
        "\n",
        "The tutorial is heavily adapted from: https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTvIwDlYvBzC"
      },
      "source": [
        "### Initial Setup\n",
        "\n",
        "Before beginning the assignment, we import the MNIST dataset, and train a simple convolutional neural network (CNN) to classify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbiiMcdNJI--",
        "outputId": "b03a637b-c757-47d9-ff23-1846dfe8c63b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.5.0 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.5.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install torch==1.5.0 torchvision==1.6.0\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.quantization\n",
        "from torch.quantization import QuantStub, DeQuantStub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCaMDWYArEXO"
      },
      "source": [
        "Load training and test data from the MNIST dataset and apply a normalizing transformation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5UuOjjrnogR",
        "outputId": "f91bf88b-1f86-4777-d3cc-4ff31f629fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 343kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.23MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.7MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=16, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG5qXPDxnUnj"
      },
      "source": [
        "Define some helper functions and classes that help us to track the statistics and accuracy with respect to the train/test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WetzHpQybN1k"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "def accuracy(output, target):\n",
        "    \"\"\" Computes the top 1 accuracy \"\"\"\n",
        "    with torch.no_grad():\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(1, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        correct_one = correct[:1].view(-1).float().sum(0, keepdim=True)\n",
        "        return correct_one.mul_(100.0 / batch_size).item()\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    \"\"\" Prints the real size of the model \"\"\"\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "def load_model(quantized_model, model):\n",
        "    \"\"\" Loads in the weights into an object meant for quantization \"\"\"\n",
        "    state_dict = model.state_dict()\n",
        "    model = model.to('cpu')\n",
        "    quantized_model.load_state_dict(state_dict)\n",
        "\n",
        "def fuse_modules(model):\n",
        "    \"\"\" Fuse together convolutions/linear layers and ReLU \"\"\"\n",
        "    torch.quantization.fuse_modules(model, [['conv1', 'relu1'],\n",
        "                                            ['conv2', 'relu2'],\n",
        "                                            ['fc1', 'relu3'],\n",
        "                                            ['fc2', 'relu4']], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l62CkyIwtSOv"
      },
      "source": [
        "Define a simple CNN that classifies MNIST images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9fL3F-7Rntog"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, q = False):\n",
        "        # By turning on Q we can turn on/off the quantization\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(256, 120, bias=False)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
        "        self.q = q\n",
        "        if q:\n",
        "          self.quant = QuantStub()\n",
        "          self.dequant = DeQuantStub()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.q:\n",
        "          x = self.quant(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        # Be careful to use reshape here instead of view\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.fc3(x)\n",
        "        if self.q:\n",
        "          x = self.dequant(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9_LdxSTb3BJ",
        "outputId": "540e9fbe-f3a4-416b-8938-de64035b7252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size (MB): 0.179057\n"
          ]
        }
      ],
      "source": [
        "net = Net(q=False).cuda()\n",
        "print_size_of_model(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nijieuxptag6"
      },
      "source": [
        "Train this CNN on the training dataset (this may take a few moments)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CzK6ohj5oNCT"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module, dataloader: DataLoader, cuda=False, q=False):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    model.train()\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = AverageMeter('loss')\n",
        "        acc = AverageMeter('train_acc')\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "              inputs = inputs.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if epoch>=3 and q:\n",
        "              model.apply(torch.quantization.disable_observer)\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss.update(loss.item(), outputs.shape[0])\n",
        "            acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
        "            if i % 100 == 0:    # print every 100 mini-batches\n",
        "                print('[%d, %5d] ' %\n",
        "                    (epoch + 1, i + 1), running_loss, acc)\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            if cuda:\n",
        "              inputs = inputs.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HixhBHaqtmZU",
        "outputId": "22964b09-97bf-46f3-e592-5f33755021eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,     1]  loss 2.301825 (2.301825) train_acc 9.375000 (9.375000)\n",
            "[1,   101]  loss 2.296545 (2.299753) train_acc 14.062500 (13.180693)\n",
            "[1,   201]  loss 2.294123 (2.295533) train_acc 20.312500 (16.969838)\n",
            "[1,   301]  loss 2.260918 (2.289851) train_acc 31.250000 (19.684385)\n",
            "[1,   401]  loss 2.229809 (2.280524) train_acc 28.125000 (22.241272)\n",
            "[1,   501]  loss 2.112481 (2.260747) train_acc 34.375000 (23.924027)\n",
            "[1,   601]  loss 1.691649 (2.207187) train_acc 56.250000 (26.000936)\n",
            "[1,   701]  loss 1.302064 (2.094674) train_acc 57.812500 (30.683845)\n",
            "[1,   801]  loss 0.603729 (1.944274) train_acc 79.687500 (35.927747)\n",
            "[1,   901]  loss 0.637056 (1.799278) train_acc 79.687500 (40.822697)\n",
            "[2,     1]  loss 0.421752 (0.421752) train_acc 84.375000 (84.375000)\n",
            "[2,   101]  loss 0.555698 (0.466051) train_acc 76.562500 (84.916460)\n",
            "[2,   201]  loss 0.367405 (0.443531) train_acc 90.625000 (85.828669)\n",
            "[2,   301]  loss 0.338774 (0.414789) train_acc 87.500000 (86.908223)\n",
            "[2,   401]  loss 0.418230 (0.392866) train_acc 85.937500 (87.612999)\n",
            "[2,   501]  loss 0.192535 (0.373555) train_acc 93.750000 (88.254741)\n",
            "[2,   601]  loss 0.267304 (0.359256) train_acc 90.625000 (88.779118)\n",
            "[2,   701]  loss 0.270399 (0.347294) train_acc 89.062500 (89.138285)\n",
            "[2,   801]  loss 0.217331 (0.334197) train_acc 95.312500 (89.565777)\n",
            "[2,   901]  loss 0.210387 (0.323724) train_acc 92.187500 (89.901845)\n",
            "[3,     1]  loss 0.179686 (0.179686) train_acc 93.750000 (93.750000)\n",
            "[3,   101]  loss 0.177956 (0.218159) train_acc 96.875000 (93.301361)\n",
            "[3,   201]  loss 0.131281 (0.212642) train_acc 96.875000 (93.625622)\n",
            "[3,   301]  loss 0.230773 (0.202948) train_acc 93.750000 (93.864203)\n",
            "[3,   401]  loss 0.160824 (0.198201) train_acc 95.312500 (94.030549)\n",
            "[3,   501]  loss 0.164737 (0.193917) train_acc 93.750000 (94.142964)\n",
            "[3,   601]  loss 0.279176 (0.192728) train_acc 92.187500 (94.121776)\n",
            "[3,   701]  loss 0.065058 (0.189104) train_acc 98.437500 (94.251516)\n",
            "[3,   801]  loss 0.084926 (0.184719) train_acc 98.437500 (94.387875)\n",
            "[3,   901]  loss 0.197474 (0.180851) train_acc 93.750000 (94.490497)\n",
            "[4,     1]  loss 0.052120 (0.052120) train_acc 98.437500 (98.437500)\n",
            "[4,   101]  loss 0.144741 (0.153190) train_acc 93.750000 (95.281559)\n",
            "[4,   201]  loss 0.058057 (0.144277) train_acc 100.000000 (95.545709)\n",
            "[4,   301]  loss 0.194177 (0.142744) train_acc 93.750000 (95.546096)\n",
            "[4,   401]  loss 0.065646 (0.140524) train_acc 96.875000 (95.624221)\n",
            "[4,   501]  loss 0.154308 (0.139291) train_acc 93.750000 (95.671158)\n",
            "[4,   601]  loss 0.096717 (0.137997) train_acc 96.875000 (95.718074)\n",
            "[4,   701]  loss 0.079012 (0.135662) train_acc 96.875000 (95.793955)\n",
            "[4,   801]  loss 0.095808 (0.134334) train_acc 95.312500 (95.870396)\n",
            "[4,   901]  loss 0.041427 (0.133144) train_acc 100.000000 (95.903857)\n",
            "[5,     1]  loss 0.122821 (0.122821) train_acc 93.750000 (93.750000)\n",
            "[5,   101]  loss 0.150619 (0.116678) train_acc 96.875000 (96.426361)\n",
            "[5,   201]  loss 0.217060 (0.120113) train_acc 95.312500 (96.284204)\n",
            "[5,   301]  loss 0.095003 (0.115354) train_acc 98.437500 (96.480482)\n",
            "[5,   401]  loss 0.178125 (0.113512) train_acc 92.187500 (96.516521)\n",
            "[5,   501]  loss 0.102078 (0.109734) train_acc 95.312500 (96.644212)\n",
            "[5,   601]  loss 0.105195 (0.108953) train_acc 98.437500 (96.612417)\n",
            "[5,   701]  loss 0.085071 (0.108335) train_acc 96.875000 (96.647646)\n",
            "[5,   801]  loss 0.170604 (0.109351) train_acc 92.187500 (96.580446)\n",
            "[5,   901]  loss 0.100234 (0.108733) train_acc 96.875000 (96.588860)\n",
            "[6,     1]  loss 0.121567 (0.121567) train_acc 95.312500 (95.312500)\n",
            "[6,   101]  loss 0.075490 (0.094121) train_acc 98.437500 (97.230817)\n",
            "[6,   201]  loss 0.064948 (0.089618) train_acc 96.875000 (97.193719)\n",
            "[6,   301]  loss 0.145593 (0.092476) train_acc 95.312500 (97.087832)\n",
            "[6,   401]  loss 0.225213 (0.093565) train_acc 92.187500 (97.050343)\n",
            "[6,   501]  loss 0.046396 (0.092195) train_acc 98.437500 (97.093313)\n",
            "[6,   601]  loss 0.098693 (0.092610) train_acc 95.312500 (97.116785)\n",
            "[6,   701]  loss 0.063563 (0.093459) train_acc 98.437500 (97.100125)\n",
            "[6,   801]  loss 0.087230 (0.092648) train_acc 96.875000 (97.122737)\n",
            "[6,   901]  loss 0.103449 (0.091624) train_acc 96.875000 (97.157672)\n",
            "[7,     1]  loss 0.120803 (0.120803) train_acc 93.750000 (93.750000)\n",
            "[7,   101]  loss 0.027874 (0.093506) train_acc 100.000000 (96.967822)\n",
            "[7,   201]  loss 0.047028 (0.085835) train_acc 98.437500 (97.178172)\n",
            "[7,   301]  loss 0.049162 (0.082928) train_acc 98.437500 (97.347384)\n",
            "[7,   401]  loss 0.040157 (0.082934) train_acc 98.437500 (97.369857)\n",
            "[7,   501]  loss 0.061389 (0.082282) train_acc 98.437500 (97.433258)\n",
            "[7,   601]  loss 0.107987 (0.084587) train_acc 95.312500 (97.363769)\n",
            "[7,   701]  loss 0.136759 (0.084009) train_acc 96.875000 (97.374287)\n",
            "[7,   801]  loss 0.036806 (0.082340) train_acc 98.437500 (97.421192)\n",
            "[7,   901]  loss 0.060247 (0.081543) train_acc 98.437500 (97.454218)\n",
            "[8,     1]  loss 0.090545 (0.090545) train_acc 96.875000 (96.875000)\n",
            "[8,   101]  loss 0.044258 (0.073398) train_acc 98.437500 (97.725866)\n",
            "[8,   201]  loss 0.049968 (0.077063) train_acc 98.437500 (97.714552)\n",
            "[8,   301]  loss 0.085269 (0.078063) train_acc 96.875000 (97.658846)\n",
            "[8,   401]  loss 0.165036 (0.079706) train_acc 93.750000 (97.560786)\n",
            "[8,   501]  loss 0.171269 (0.078292) train_acc 95.312500 (97.632859)\n",
            "[8,   601]  loss 0.014902 (0.078714) train_acc 100.000000 (97.634151)\n",
            "[8,   701]  loss 0.018776 (0.076614) train_acc 100.000000 (97.693028)\n",
            "[8,   801]  loss 0.077634 (0.075756) train_acc 95.312500 (97.688436)\n",
            "[8,   901]  loss 0.072130 (0.074623) train_acc 96.875000 (97.702206)\n",
            "[9,     1]  loss 0.023216 (0.023216) train_acc 100.000000 (100.000000)\n",
            "[9,   101]  loss 0.025362 (0.075065) train_acc 100.000000 (97.787748)\n",
            "[9,   201]  loss 0.023575 (0.075787) train_acc 100.000000 (97.776741)\n",
            "[9,   301]  loss 0.056463 (0.071825) train_acc 98.437500 (97.767857)\n",
            "[9,   401]  loss 0.015321 (0.068792) train_acc 98.437500 (97.868610)\n",
            "[9,   501]  loss 0.022236 (0.067967) train_acc 100.000000 (97.922904)\n",
            "[9,   601]  loss 0.057575 (0.068147) train_acc 98.437500 (97.896735)\n",
            "[9,   701]  loss 0.082051 (0.066788) train_acc 98.437500 (97.924840)\n",
            "[9,   801]  loss 0.064518 (0.067079) train_acc 95.312500 (97.906913)\n",
            "[9,   901]  loss 0.059543 (0.067299) train_acc 96.875000 (97.905105)\n",
            "[10,     1]  loss 0.066471 (0.066471) train_acc 98.437500 (98.437500)\n",
            "[10,   101]  loss 0.049779 (0.061040) train_acc 98.437500 (98.220916)\n",
            "[10,   201]  loss 0.012248 (0.062884) train_acc 100.000000 (98.041045)\n",
            "[10,   301]  loss 0.017566 (0.060775) train_acc 100.000000 (98.105274)\n",
            "[10,   401]  loss 0.074730 (0.061761) train_acc 98.437500 (98.153055)\n",
            "[10,   501]  loss 0.009322 (0.062308) train_acc 100.000000 (98.110030)\n",
            "[10,   601]  loss 0.028268 (0.062351) train_acc 100.000000 (98.122920)\n",
            "[10,   701]  loss 0.056530 (0.062900) train_acc 95.312500 (98.092011)\n",
            "[10,   801]  loss 0.147855 (0.062269) train_acc 96.875000 (98.117587)\n",
            "[10,   901]  loss 0.045884 (0.062466) train_acc 98.437500 (98.101068)\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, trainloader, cuda=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJggxnCVuRxU"
      },
      "source": [
        "Now that the CNN has been trained, let's test it on our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y27_n-djuEdz",
        "outputId": "8e67d498-b18d-4be9-95fe-7e8706d23c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 98.09% - FP32\n"
          ]
        }
      ],
      "source": [
        "score = test(net, testloader, cuda=True)\n",
        "print('Accuracy of the network on the test images: {}% - FP32'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lp-ElDsrKua"
      },
      "source": [
        "### Post-training quantization\n",
        "\n",
        "Define a new quantized network architeture, where we also define the quantization and dequantization stubs that will be important at the start and at the end.\n",
        "\n",
        "Next, we’ll “fuse modules”; this can both make the model faster by saving on memory access while also improving numerical accuracy. While this can be used with any model, this is especially common with quantized models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X-nQWDXrhItv"
      },
      "outputs": [],
      "source": [
        "qnet = Net(q=True)\n",
        "load_model(qnet, net)\n",
        "fuse_modules(qnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiaQkj6wJuC6"
      },
      "source": [
        "In general, we have the following process (Post Training Quantization):\n",
        "\n",
        "1. Prepare: we insert some observers to the model to observe the statistics of a Tensor, for example, min/max values of the Tensor\n",
        "2. Calibration: We run the model with some representative sample data, this will allow the observers to record the Tensor statistics\n",
        "3. Convert: Based on the calibrated model, we can figure out the quantization parameters for the mapping function and convert the floating point operators to quantized operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ZaMV4bUb6-",
        "outputId": "77098546-d269-44d8-a1b6-6d60cac12029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
            "Post Training Quantization Prepare: Inserting Observers\n",
            "\n",
            " Conv1: After observer insertion \n",
            "\n",
            " ConvReLU2d(\n",
            "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "  (1): ReLU()\n",
            "  (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            ")\n",
            "Post Training Quantization: Calibration done\n",
            "Post Training Quantization: Convert done\n",
            "\n",
            " Conv1: After fusion and quantization \n",
            "\n",
            " QuantizedConvReLU2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.05912807211279869, zero_point=0, bias=False)\n",
            "Size of model after quantization\n",
            "Size (MB): 0.050084\n"
          ]
        }
      ],
      "source": [
        "qnet.qconfig = torch.quantization.default_qconfig\n",
        "print(qnet.qconfig)\n",
        "torch.quantization.prepare(qnet, inplace=True)\n",
        "print('Post Training Quantization Prepare: Inserting Observers')\n",
        "print('\\n Conv1: After observer insertion \\n\\n', qnet.conv1)\n",
        "\n",
        "test(qnet, trainloader, cuda=False)\n",
        "print('Post Training Quantization: Calibration done')\n",
        "torch.quantization.convert(qnet, inplace=True)\n",
        "print('Post Training Quantization: Convert done')\n",
        "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
        "print(\"Size of model after quantization\")\n",
        "print_size_of_model(qnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbDvGBtMavCO",
        "outputId": "9a1bb06b-dee0-4293-ac8a-05c4a13d7868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the fused and quantized network on the test images: 98.11% - INT8\n"
          ]
        }
      ],
      "source": [
        "score = test(qnet, testloader, cuda=False)\n",
        "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcv6Gi45lZ4L"
      },
      "source": [
        "We can also define a cusom quantization configuration, where we replace the default observers and instead of quantising with respect to max/min we can take an average of the observed max/min, hopefully for a better generalization performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNj6TNFu1ljn",
        "outputId": "054066c3-0c61-4a94-df74-3d6dcd71f328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
            "Post Training Quantization Prepare: Inserting Observers\n",
            "\n",
            " Conv1: After observer insertion \n",
            "\n",
            " ConvReLU2d(\n",
            "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "  (1): ReLU()\n",
            "  (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Post Training Quantization: Calibration done\n",
            "Post Training Quantization: Convert done\n",
            "\n",
            " Conv1: After fusion and quantization \n",
            "\n",
            " QuantizedConvReLU2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.05865493789315224, zero_point=0, bias=False)\n",
            "Size of model after quantization\n",
            "Size (MB): 0.050084\n",
            "Accuracy of the fused and quantized network on the test images: 98.13% - INT8\n"
          ]
        }
      ],
      "source": [
        "from torch.quantization.observer import MovingAverageMinMaxObserver\n",
        "\n",
        "qnet = Net(q=True)\n",
        "load_model(qnet, net)\n",
        "fuse_modules(qnet)\n",
        "\n",
        "qnet.qconfig = torch.quantization.QConfig(\n",
        "                                      activation=MovingAverageMinMaxObserver.with_args(reduce_range=True),\n",
        "                                      weight=MovingAverageMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
        "print(qnet.qconfig)\n",
        "torch.quantization.prepare(qnet, inplace=True)\n",
        "print('Post Training Quantization Prepare: Inserting Observers')\n",
        "print('\\n Conv1: After observer insertion \\n\\n', qnet.conv1)\n",
        "\n",
        "test(qnet, trainloader, cuda=False)\n",
        "print('Post Training Quantization: Calibration done')\n",
        "torch.quantization.convert(qnet, inplace=True)\n",
        "print('Post Training Quantization: Convert done')\n",
        "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
        "print(\"Size of model after quantization\")\n",
        "print_size_of_model(qnet)\n",
        "score = test(qnet, testloader, cuda=False)\n",
        "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LXNCT7fgcMx"
      },
      "source": [
        "In addition, we can significantly improve on the accuracy simply by using a different quantization configuration. We repeat the same exercise with the recommended configuration for quantizing for arm64 architecture (qnnpack). This configuration does the following:\n",
        "Quantizes weights on a per-channel basis. It\n",
        "uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-nZq5yF_gWBs"
      },
      "outputs": [],
      "source": [
        "qnet = Net(q=True)\n",
        "load_model(qnet, net)\n",
        "fuse_modules(qnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXv5pAwVlGFh",
        "outputId": "8a112f5f-020f-4138-eff9-7aaf9c463479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=False){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
            "Size of model after quantization\n",
            "Size (MB): 0.050084\n"
          ]
        }
      ],
      "source": [
        "qnet.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
        "print(qnet.qconfig)\n",
        "\n",
        "torch.quantization.prepare(qnet, inplace=True)\n",
        "test(qnet, trainloader, cuda=False)\n",
        "torch.quantization.convert(qnet, inplace=True)\n",
        "print(\"Size of model after quantization\")\n",
        "print_size_of_model(qnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Vjyayimv8n",
        "outputId": "2b63ad28-821e-4193-80c8-ff9ebbd3a30c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the fused and quantized network on the test images: 98.02% - INT8\n"
          ]
        }
      ],
      "source": [
        "score = test(qnet, testloader, cuda=False)\n",
        "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A_G3tsasU6U"
      },
      "source": [
        "### Quantization aware training\n",
        "\n",
        "Quantization-aware training (QAT) is the quantization method that typically results in the highest accuracy. With QAT, all weights and activations are “fake quantized” during both the forward and backward passes of training: that is, float values are rounded to mimic int8 values, but all computations are still done with floating point numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o-mGba7QsXzf",
        "outputId": "c18ca8b2-0d3e-4abe-d89b-a98778395224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Conv1: After fusion and quantization \n",
            "\n",
            " ConvReLU2d(\n",
            "  1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False\n",
            "  (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
            "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False\n",
            "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
            "  )\n",
            "  (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
            "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
            "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
            "  )\n",
            ")\n",
            "[1,     1]  loss 2.304440 (2.304440) train_acc 9.375000 (9.375000)\n",
            "[1,   101]  loss 2.295077 (2.302561) train_acc 23.437500 (11.958540)\n",
            "[1,   201]  loss 2.294279 (2.300279) train_acc 20.312500 (13.751555)\n",
            "[1,   301]  loss 2.288170 (2.297614) train_acc 18.750000 (16.190822)\n",
            "[1,   401]  loss 2.276252 (2.294031) train_acc 26.562500 (18.691552)\n",
            "[1,   501]  loss 2.260778 (2.289075) train_acc 37.500000 (22.080838)\n",
            "[1,   601]  loss 2.237988 (2.282447) train_acc 57.812500 (26.227121)\n",
            "[1,   701]  loss 2.189206 (2.272647) train_acc 60.937500 (29.981723)\n",
            "[1,   801]  loss 2.111011 (2.257459) train_acc 67.187500 (33.637640)\n",
            "[1,   901]  loss 1.935515 (2.232754) train_acc 71.875000 (37.179176)\n",
            "[2,     1]  loss 1.815505 (1.815505) train_acc 78.125000 (78.125000)\n",
            "[2,   101]  loss 1.518828 (1.718833) train_acc 81.250000 (70.327970)\n",
            "[2,   201]  loss 1.125992 (1.527937) train_acc 75.000000 (72.046020)\n",
            "[2,   301]  loss 0.826078 (1.338423) train_acc 81.250000 (73.411545)\n",
            "[2,   401]  loss 0.558374 (1.179151) train_acc 84.375000 (74.941552)\n",
            "[2,   501]  loss 0.396275 (1.057335) train_acc 87.500000 (76.515719)\n",
            "[2,   601]  loss 0.498701 (0.963201) train_acc 84.375000 (77.924813)\n",
            "[2,   701]  loss 0.374757 (0.888694) train_acc 89.062500 (79.130260)\n",
            "[2,   801]  loss 0.253134 (0.826470) train_acc 92.187500 (80.307818)\n",
            "[2,   901]  loss 0.281888 (0.772517) train_acc 90.625000 (81.407811)\n",
            "[3,     1]  loss 0.248566 (0.248566) train_acc 92.187500 (92.187500)\n",
            "[3,   101]  loss 0.350981 (0.317731) train_acc 87.500000 (90.841584)\n",
            "[3,   201]  loss 0.384525 (0.295504) train_acc 89.062500 (91.246891)\n",
            "[3,   301]  loss 0.380129 (0.282210) train_acc 87.500000 (91.491902)\n",
            "[3,   401]  loss 0.183598 (0.271671) train_acc 93.750000 (91.821228)\n",
            "[3,   501]  loss 0.197732 (0.261543) train_acc 92.187500 (92.159431)\n",
            "[3,   601]  loss 0.251078 (0.253413) train_acc 90.625000 (92.335691)\n",
            "[3,   701]  loss 0.266169 (0.243799) train_acc 89.062500 (92.611002)\n",
            "[3,   801]  loss 0.207979 (0.238297) train_acc 92.187500 (92.774657)\n",
            "[3,   901]  loss 0.239427 (0.232113) train_acc 95.312500 (92.966149)\n",
            "[4,     1]  loss 0.170995 (0.170995) train_acc 95.312500 (95.312500)\n",
            "[4,   101]  loss 0.225764 (0.173136) train_acc 89.062500 (94.755569)\n",
            "[4,   201]  loss 0.306369 (0.167502) train_acc 93.750000 (94.986007)\n",
            "[4,   301]  loss 0.109877 (0.163847) train_acc 96.875000 (95.187915)\n",
            "[4,   401]  loss 0.057776 (0.163052) train_acc 98.437500 (95.187812)\n",
            "[4,   501]  loss 0.173951 (0.161193) train_acc 95.312500 (95.215818)\n",
            "[4,   601]  loss 0.126010 (0.158190) train_acc 93.750000 (95.278702)\n",
            "[4,   701]  loss 0.120520 (0.155311) train_acc 95.312500 (95.310271)\n",
            "[4,   801]  loss 0.053902 (0.152130) train_acc 98.437500 (95.388577)\n",
            "[4,   901]  loss 0.165055 (0.149260) train_acc 93.750000 (95.463374)\n",
            "[5,     1]  loss 0.122501 (0.122501) train_acc 95.312500 (95.312500)\n",
            "[5,   101]  loss 0.033085 (0.117055) train_acc 100.000000 (96.163366)\n",
            "[5,   201]  loss 0.150807 (0.119394) train_acc 96.875000 (96.268657)\n",
            "[5,   301]  loss 0.162032 (0.120572) train_acc 93.750000 (96.246885)\n",
            "[5,   401]  loss 0.097207 (0.119384) train_acc 96.875000 (96.282731)\n",
            "[5,   501]  loss 0.109579 (0.116861) train_acc 96.875000 (96.369760)\n",
            "[5,   601]  loss 0.116021 (0.116181) train_acc 95.312500 (96.404430)\n",
            "[5,   701]  loss 0.164642 (0.115847) train_acc 95.312500 (96.406919)\n",
            "[5,   801]  loss 0.084875 (0.114979) train_acc 95.312500 (96.445849)\n",
            "[5,   901]  loss 0.054605 (0.114195) train_acc 98.437500 (96.457062)\n",
            "[6,     1]  loss 0.124124 (0.124124) train_acc 96.875000 (96.875000)\n",
            "[6,   101]  loss 0.056028 (0.099250) train_acc 98.437500 (97.107054)\n",
            "[6,   201]  loss 0.096668 (0.101031) train_acc 98.437500 (96.952736)\n",
            "[6,   301]  loss 0.125103 (0.099333) train_acc 96.875000 (96.978821)\n",
            "[6,   401]  loss 0.056739 (0.098409) train_acc 98.437500 (96.984102)\n",
            "[6,   501]  loss 0.074035 (0.098421) train_acc 98.437500 (97.005988)\n",
            "[6,   601]  loss 0.078242 (0.096662) train_acc 95.312500 (97.030990)\n",
            "[6,   701]  loss 0.020188 (0.095526) train_acc 100.000000 (97.051088)\n",
            "[6,   801]  loss 0.053327 (0.095198) train_acc 98.437500 (97.058365)\n",
            "[6,   901]  loss 0.066734 (0.095037) train_acc 96.875000 (97.072697)\n",
            "[7,     1]  loss 0.027886 (0.027886) train_acc 98.437500 (98.437500)\n",
            "[7,   101]  loss 0.019469 (0.081202) train_acc 100.000000 (97.602104)\n",
            "[7,   201]  loss 0.123808 (0.085864) train_acc 98.437500 (97.403607)\n",
            "[7,   301]  loss 0.130049 (0.085862) train_acc 95.312500 (97.383721)\n",
            "[7,   401]  loss 0.094753 (0.082690) train_acc 96.875000 (97.514027)\n",
            "[7,   501]  loss 0.113919 (0.082592) train_acc 96.875000 (97.464446)\n",
            "[7,   601]  loss 0.098542 (0.083274) train_acc 95.312500 (97.433964)\n",
            "[7,   701]  loss 0.008227 (0.083886) train_acc 100.000000 (97.447842)\n",
            "[7,   801]  loss 0.164467 (0.083901) train_acc 93.750000 (97.425094)\n",
            "[7,   901]  loss 0.055887 (0.082425) train_acc 98.437500 (97.473294)\n",
            "[8,     1]  loss 0.015187 (0.015187) train_acc 100.000000 (100.000000)\n",
            "[8,   101]  loss 0.047262 (0.073763) train_acc 98.437500 (97.679455)\n",
            "[8,   201]  loss 0.163617 (0.076628) train_acc 95.312500 (97.605721)\n",
            "[8,   301]  loss 0.046572 (0.077008) train_acc 98.437500 (97.622508)\n",
            "[8,   401]  loss 0.060605 (0.078516) train_acc 96.875000 (97.556889)\n",
            "[8,   501]  loss 0.147733 (0.076814) train_acc 96.875000 (97.604790)\n",
            "[8,   601]  loss 0.042546 (0.076574) train_acc 98.437500 (97.654950)\n",
            "[8,   701]  loss 0.062950 (0.075690) train_acc 96.875000 (97.675196)\n",
            "[8,   801]  loss 0.083476 (0.075734) train_acc 98.437500 (97.661127)\n",
            "[8,   901]  loss 0.075650 (0.074651) train_acc 98.437500 (97.710877)\n",
            "[9,     1]  loss 0.146265 (0.146265) train_acc 96.875000 (96.875000)\n",
            "[9,   101]  loss 0.095461 (0.061736) train_acc 93.750000 (98.035272)\n",
            "[9,   201]  loss 0.029066 (0.065671) train_acc 98.437500 (97.947761)\n",
            "[9,   301]  loss 0.037797 (0.065458) train_acc 98.437500 (97.918397)\n",
            "[9,   401]  loss 0.100056 (0.066495) train_acc 96.875000 (97.864713)\n",
            "[9,   501]  loss 0.039995 (0.067219) train_acc 98.437500 (97.869885)\n",
            "[9,   601]  loss 0.011912 (0.066606) train_acc 100.000000 (97.914933)\n",
            "[9,   701]  loss 0.227830 (0.067995) train_acc 95.312500 (97.900321)\n",
            "[9,   801]  loss 0.011241 (0.067192) train_acc 100.000000 (97.926420)\n",
            "[9,   901]  loss 0.022519 (0.067483) train_acc 100.000000 (97.946726)\n",
            "[10,     1]  loss 0.040864 (0.040864) train_acc 98.437500 (98.437500)\n",
            "[10,   101]  loss 0.122101 (0.060079) train_acc 98.437500 (98.097153)\n",
            "[10,   201]  loss 0.193999 (0.060114) train_acc 95.312500 (98.118781)\n",
            "[10,   301]  loss 0.145133 (0.062842) train_acc 98.437500 (98.074128)\n",
            "[10,   401]  loss 0.017767 (0.062216) train_acc 100.000000 (98.082918)\n",
            "[10,   501]  loss 0.061780 (0.063057) train_acc 96.875000 (98.060130)\n",
            "[10,   601]  loss 0.009336 (0.062604) train_acc 100.000000 (98.076123)\n",
            "[10,   701]  loss 0.053455 (0.062203) train_acc 96.875000 (98.092011)\n",
            "[10,   801]  loss 0.147072 (0.062073) train_acc 96.875000 (98.103933)\n",
            "[10,   901]  loss 0.033938 (0.061321) train_acc 100.000000 (98.130549)\n",
            "Finished Training\n",
            "Size of model after quantization\n",
            "Size (MB): 0.050084\n",
            "Accuracy of the fused and quantized network (trained quantized) on the test images: 98.0% - INT8\n"
          ]
        }
      ],
      "source": [
        "qnet = Net(q=True)\n",
        "fuse_modules(qnet)\n",
        "qnet.qconfig = torch.quantization.get_default_qat_qconfig('qnnpack')\n",
        "torch.quantization.prepare_qat(qnet, inplace=True)\n",
        "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
        "qnet=qnet.cuda()\n",
        "train(qnet, trainloader, cuda=True)\n",
        "qnet = qnet.cpu()\n",
        "torch.quantization.convert(qnet, inplace=True)\n",
        "print(\"Size of model after quantization\")\n",
        "print_size_of_model(qnet)\n",
        "\n",
        "score = test(qnet, testloader, cuda=False)\n",
        "print('Accuracy of the fused and quantized network (trained quantized) on the test images: {}% - INT8'.format(score))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
